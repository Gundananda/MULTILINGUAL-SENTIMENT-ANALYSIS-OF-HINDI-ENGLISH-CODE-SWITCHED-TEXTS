# ðŸ’¬ Codeâ€‘Mixed Sentiment Analysis with BiLSTM (TensorFlow/Keras)

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-FF6F00?logo=tensorflow&logoColor=white)](https://www.tensorflow.org/)
[![Keras](https://img.shields.io/badge/Keras-2.x-D00000?logo=keras&logoColor=white)](https://keras.io/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.x-F7931E?logo=scikitlearn&logoColor=white)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

Endâ€‘toâ€‘end pipeline for sentiment classification on codeâ€‘mixed (Hinglish) tweets using regex cleaning, Keras Tokenizer, and a BiLSTM classifier.

</div>

---

## ðŸ“Œ Overview

This repository trains and evaluates a BiLSTM model on Sentimixâ€‘style CSVs (train/val/test) to classify tweets into negative, neutral, and positive sentiment. It includes consistent preprocessing, tokenization, model training, evaluation with classification reports, and simple inference for new texts.

Note: This is a research/education project.

---

## âœ¨ Key Features

| Feature | Description |
| :--- | :--- |
| ðŸ§¹ Preprocessing | Lowercasing; removes URLs, @mentions; converts hashtags to words; compresses elongated chars; strips punctuation and extra spaces. |
| ðŸ”¤ Tokenization | Keras Tokenizer with 20k vocabulary and post-padding to 100 tokens; OOV handled via <UNK>. |
| ðŸ§  Model | Embedding â†’ Bidirectional LSTM(128, return_sequences) â†’ GlobalAveragePooling1D â†’ Dense(64, ReLU) â†’ Dropout(0.3) â†’ Softmax(3). |
| ðŸ“Š Evaluation | Classification reports (precision/recall/F1) for validation and test sets; confusion matrices generated in notebook. |
| ðŸš€ Inference | Clean, tokenize, and predict sentiments for new short texts. |

---

## ðŸ“‚ Project Structure

```plaintext
sentimix-bilstm/
â”œâ”€â”€ notebook.ipynb                 # Main workflow (training, evaluation, inference)
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ data/                          # Place your CSVs here (not in repo)
    â”œâ”€â”€ sentimix_train.csv
    â”œâ”€â”€ sentimix_val.csv
    â””â”€â”€ sentimix_test.csv
```

---

## ðŸ“¦ Dataset

- Expected CSV columns:
  - tweet: raw text
  - sentiment: one of {negative, neutral, positive}
- Files used:
  - sentimix_train.csv, sentimix_val.csv, sentimix_test.csv
- Cleaning produces a text_clean column used for tokenization.

Update paths in the notebook if your files live elsewhere (e.g., /content/â€¦).

---

## ðŸ§  Technical Details

- Vocabulary size: 20,000
- Max sequence length: 100
- Labels (sorted from training): ['negative', 'neutral', 'positive']
- Model
  - Embedding(VOCAB_SIZE=20k, 128) â†’ BiLSTM(128, return_sequences=True)
  - GlobalAveragePooling1D
  - Dense(64, activation="relu") + Dropout(0.3)
  - Dense(3, activation="softmax")
- Training
  - Loss: categorical_crossentropy
  - Optimizer: Adam
  - Metrics: accuracy
  - Epochs: 5
  - Batch size: 64

---

## ðŸš€ Getting Started

### Installation
```bash
pip install tensorflow numpy pandas scikit-learn matplotlib seaborn
```

### Data Preparation
- Place train/val/test CSVs under data/ or adjust the notebook paths:
  - /content/sentimix_train.csv
  - /content/sentimix_val.csv
  - /content/sentimix_test.csv

### Run
- Open notebook.ipynb and execute cells in order:
  1) Load CSVs
  2) Clean text
  3) Tokenize and pad
  4) Encode labels
  5) Build and train BiLSTM
  6) Evaluate on val/test
  7) Run inference on sample texts

---

## ðŸ“Š Results

Your run produced:
- Validation accuracy: 0.59
  - Macro F1: 0.59, Weighted F1: 0.59
- Test accuracy: 0.62
  - Macro F1: 0.63, Weighted F1: 0.62

Common error pattern: neutral is the hardest class and gets confused with polar classes.

---



## ðŸ”§ Tips & Next Steps

- Try pretrained embeddings (fastText, GloVe) or character/subword tokenizers.
- Fineâ€‘tune transformer baselines (mBERT, XLMâ€‘R) for codeâ€‘mixed text.
- Address class imbalance with class weights or focal loss.
- Add early stopping, learning rate schedules, and more epochs for higher accuracy.
- Evaluate with macroâ€‘F1 as a primary metric for imbalanced multiâ€‘class settings.

---

## ðŸ§ª Reproducibility

- Save artifacts:
  - tokenizer.json
  - label2id.json
  - model.h5 (or SavedModel)
- Fix random seeds and log dataset versions.
- Keep preprocessing identical between train and inference.

---

## ðŸ“„ License

Released under the MIT License. See LICENSE.


